{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ü•î Phase 5: Model Selection & Architecture Design\n",
        "\n",
        "This notebook defines the deep learning model architecture for potato disease classification.\n",
        "\n",
        "**Features:**\n",
        "- Transfer learning with pre-trained models (MobileNetV2, EfficientNet, ResNet)\n",
        "- Custom classification head for 3-class potato disease detection\n",
        "- Mobile-optimized architecture options\n",
        "- Regularization techniques to prevent overfitting\n",
        "- Model comparison and selection"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Mount Google Drive & Setup"
      ],
      "metadata": {
        "id": "mount_header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_drive"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "MOUNT_PATH = '/content/drive'\n",
        "\n",
        "def mount_drive():\n",
        "    if os.path.exists(os.path.join(MOUNT_PATH, 'MyDrive')):\n",
        "        print('‚úÖ Google Drive is already mounted!')\n",
        "        return True\n",
        "    if os.path.exists(MOUNT_PATH):\n",
        "        try:\n",
        "            drive.flush_and_unmount()\n",
        "        except:\n",
        "            pass\n",
        "        if os.path.exists(MOUNT_PATH):\n",
        "            try:\n",
        "                shutil.rmtree(MOUNT_PATH)\n",
        "            except:\n",
        "                pass\n",
        "    try:\n",
        "        drive.mount(MOUNT_PATH)\n",
        "        print('‚úÖ Google Drive mounted successfully!')\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f'‚ùå Mount failed: {e}')\n",
        "        return False\n",
        "\n",
        "mount_drive()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and import dependencies\n",
        "!pip install -q tensorflow keras matplotlib seaborn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.applications import (\n",
        "    MobileNetV2,\n",
        "    EfficientNetB0,\n",
        "    ResNet50,\n",
        "    VGG16\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "print(f\"‚úÖ TensorFlow version: {tf.__version__}\")\n",
        "print(f\"‚úÖ Keras version: {keras.__version__}\")\n",
        "\n",
        "# Check GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"üöÄ GPU detected: {gpus[0].name}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected, using CPU\")"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Configuration"
      ],
      "metadata": {
        "id": "config_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== CONFIGURATION =====\n",
        "\n",
        "# Dataset paths\n",
        "DATASET_DIR = \"/content/drive/MyDrive/DrukFarm/data/final_potato_dataset\"\n",
        "MODEL_SAVE_DIR = \"/content/drive/MyDrive/DrukFarm/models\"\n",
        "\n",
        "# Model parameters\n",
        "IMG_SIZE = (224, 224)       # Input image size\n",
        "IMG_SHAPE = (224, 224, 3)   # Including channels\n",
        "NUM_CLASSES = 3             # Early_Blight, Late_Blight, Healthy\n",
        "CLASS_NAMES = ['Early_Blight', 'Healthy', 'Late_Blight']  # Alphabetical order\n",
        "\n",
        "# Training parameters (for reference)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.0001\n",
        "EPOCHS = 50\n",
        "\n",
        "# Create model save directory\n",
        "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Configuration loaded!\")\n",
        "print(f\"\\nüìÅ Dataset: {DATASET_DIR}\")\n",
        "print(f\"üìÇ Models will be saved to: {MODEL_SAVE_DIR}\")\n",
        "print(f\"\\nüìä Model parameters:\")\n",
        "print(f\"   ‚Ä¢ Input size: {IMG_SIZE}\")\n",
        "print(f\"   ‚Ä¢ Number of classes: {NUM_CLASSES}\")\n",
        "print(f\"   ‚Ä¢ Classes: {CLASS_NAMES}\")"
      ],
      "metadata": {
        "id": "configuration"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model Architecture: MobileNetV2 (Recommended)\n",
        "\n",
        "**Why MobileNetV2?**\n",
        "- ‚úÖ Lightweight & fast inference\n",
        "- ‚úÖ Optimized for mobile/edge deployment\n",
        "- ‚úÖ Excellent accuracy-to-size ratio\n",
        "- ‚úÖ Pre-trained on ImageNet (1.4M images)"
      ],
      "metadata": {
        "id": "mobilenet_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mobilenet_model(input_shape, num_classes, fine_tune_layers=20):\n",
        "    \"\"\"\n",
        "    Create MobileNetV2-based model for potato disease classification.\n",
        "    \n",
        "    Architecture:\n",
        "    - Base: MobileNetV2 (pre-trained on ImageNet)\n",
        "    - Head: Global Average Pooling ‚Üí Dense(256) ‚Üí Dropout ‚Üí Dense(num_classes)\n",
        "    \"\"\"\n",
        "    # Load pre-trained MobileNetV2 (without top classification layers)\n",
        "    base_model = MobileNetV2(\n",
        "        input_shape=input_shape,\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    \n",
        "    # Freeze base model layers (except last fine_tune_layers)\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers[:-fine_tune_layers]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # Build classification head\n",
        "    model = models.Sequential([\n",
        "        # Input preprocessing\n",
        "        layers.InputLayer(input_shape=input_shape),\n",
        "        \n",
        "        # Preprocessing (MobileNetV2 specific)\n",
        "        layers.Rescaling(1./127.5, offset=-1),  # Scale to [-1, 1]\n",
        "        \n",
        "        # Feature extraction backbone\n",
        "        base_model,\n",
        "        \n",
        "        # Classification head\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(num_classes, activation='softmax', name='output')\n",
        "    ], name='PotatoDisease_MobileNetV2')\n",
        "    \n",
        "    return model, base_model\n",
        "\n",
        "\n",
        "# Create model\n",
        "mobilenet_model, mobilenet_base = create_mobilenet_model(IMG_SHAPE, NUM_CLASSES)\n",
        "\n",
        "# Display summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üì± MobileNetV2 Architecture\")\n",
        "print(\"=\" * 60)\n",
        "mobilenet_model.summary()\n",
        "\n",
        "# Count parameters\n",
        "trainable_params = int(sum([tf.keras.backend.count_params(w) for w in mobilenet_model.trainable_weights]))\n",
        "non_trainable_params = int(sum([tf.keras.backend.count_params(w) for w in mobilenet_model.non_trainable_weights]))\n",
        "print(f\"\\nüìä Parameters:\")\n",
        "print(f\"   ‚Ä¢ Trainable: {trainable_params:,}\")\n",
        "print(f\"   ‚Ä¢ Non-trainable: {non_trainable_params:,}\")\n",
        "print(f\"   ‚Ä¢ Total: {trainable_params + non_trainable_params:,}\")"
      ],
      "metadata": {
        "id": "create_mobilenet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Alternative: EfficientNetB0 (Higher Accuracy)\n",
        "\n",
        "**Why EfficientNetB0?**\n",
        "- ‚úÖ State-of-the-art accuracy\n",
        "- ‚úÖ Compound scaling architecture\n",
        "- ‚úÖ More efficient than ResNet/VGG\n",
        "- ‚ö†Ô∏è Slightly larger than MobileNetV2"
      ],
      "metadata": {
        "id": "efficientnet_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_efficientnet_model(input_shape, num_classes, fine_tune_layers=30):\n",
        "    \"\"\"\n",
        "    Create EfficientNetB0-based model for potato disease classification.\n",
        "    \"\"\"\n",
        "    # Load pre-trained EfficientNetB0\n",
        "    base_model = EfficientNetB0(\n",
        "        input_shape=input_shape,\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    \n",
        "    # Freeze base model layers\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers[:-fine_tune_layers]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # Build model\n",
        "    model = models.Sequential([\n",
        "        layers.InputLayer(input_shape=input_shape),\n",
        "        \n",
        "        # EfficientNet has built-in preprocessing\n",
        "        base_model,\n",
        "        \n",
        "        # Classification head\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax', name='output')\n",
        "    ], name='PotatoDisease_EfficientNetB0')\n",
        "    \n",
        "    return model, base_model\n",
        "\n",
        "\n",
        "# Create model\n",
        "efficientnet_model, efficientnet_base = create_efficientnet_model(IMG_SHAPE, NUM_CLASSES)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚ö° EfficientNetB0 Architecture\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Count parameters\n",
        "trainable_params = int(sum([tf.keras.backend.count_params(w) for w in efficientnet_model.trainable_weights]))\n",
        "non_trainable_params = int(sum([tf.keras.backend.count_params(w) for w in efficientnet_model.non_trainable_weights]))\n",
        "print(f\"\\nüìä Parameters:\")\n",
        "print(f\"   ‚Ä¢ Trainable: {trainable_params:,}\")\n",
        "print(f\"   ‚Ä¢ Non-trainable: {non_trainable_params:,}\")\n",
        "print(f\"   ‚Ä¢ Total: {trainable_params + non_trainable_params:,}\")"
      ],
      "metadata": {
        "id": "create_efficientnet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Alternative: Custom Lightweight CNN\n",
        "\n",
        "**Why Custom CNN?**\n",
        "- ‚úÖ Smallest model size\n",
        "- ‚úÖ Fastest inference\n",
        "- ‚úÖ Full control over architecture\n",
        "- ‚ö†Ô∏è May need more training data"
      ],
      "metadata": {
        "id": "custom_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_custom_cnn(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Create a custom lightweight CNN from scratch.\n",
        "    Optimized for small datasets and fast inference.\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.InputLayer(input_shape=input_shape),\n",
        "        \n",
        "        # Normalization\n",
        "        layers.Rescaling(1./255),\n",
        "        \n",
        "        # Block 1: 32 filters\n",
        "        layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        \n",
        "        # Block 2: 64 filters\n",
        "        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        \n",
        "        # Block 3: 128 filters\n",
        "        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        \n",
        "        # Block 4: 256 filters\n",
        "        layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        \n",
        "        # Classification head\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(num_classes, activation='softmax', name='output')\n",
        "    ], name='PotatoDisease_CustomCNN')\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "# Create model\n",
        "custom_model = create_custom_cnn(IMG_SHAPE, NUM_CLASSES)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üîß Custom Lightweight CNN Architecture\")\n",
        "print(\"=\" * 60)\n",
        "custom_model.summary()\n",
        "\n",
        "# Count parameters\n",
        "total_params = int(custom_model.count_params())\n",
        "print(f\"\\nüìä Total Parameters: {total_params:,}\")"
      ],
      "metadata": {
        "id": "create_custom_cnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Model Comparison"
      ],
      "metadata": {
        "id": "comparison_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models(models_dict):\n",
        "    \"\"\"\n",
        "    Compare different model architectures.\n",
        "    \"\"\"\n",
        "    comparison = []\n",
        "    \n",
        "    for name, model in models_dict.items():\n",
        "        total_params = int(model.count_params())\n",
        "        trainable = int(sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]))\n",
        "        \n",
        "        # Estimate model size (4 bytes per parameter)\n",
        "        size_mb = (total_params * 4) / (1024 * 1024)\n",
        "        \n",
        "        comparison.append({\n",
        "            'Model': name,\n",
        "            'Total Params': f\"{total_params:,}\",\n",
        "            'Trainable Params': f\"{trainable:,}\",\n",
        "            'Size (MB)': f\"{size_mb:.1f}\",\n",
        "            'Layers': len(model.layers)\n",
        "        })\n",
        "    \n",
        "    return comparison\n",
        "\n",
        "\n",
        "# Compare all models\n",
        "models_to_compare = {\n",
        "    'MobileNetV2': mobilenet_model,\n",
        "    'EfficientNetB0': efficientnet_model,\n",
        "    'Custom CNN': custom_model\n",
        "}\n",
        "\n",
        "comparison = compare_models(models_to_compare)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìä MODEL COMPARISON\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Print as table\n",
        "print(f\"\\n{'Model':<18} {'Total Params':<15} {'Trainable':<15} {'Size (MB)':<12} {'Layers'}\")\n",
        "print(\"-\" * 70)\n",
        "for c in comparison:\n",
        "    print(f\"{c['Model']:<18} {c['Total Params']:<15} {c['Trainable Params']:<15} {c['Size (MB)']:<12} {c['Layers']}\")\n",
        "\n",
        "print(\"\\nüìã RECOMMENDATION:\")\n",
        "print(\"   üèÜ MobileNetV2 - Best balance of accuracy and efficiency\")\n",
        "print(\"   ‚ö° EfficientNetB0 - Highest accuracy potential\")\n",
        "print(\"   üîß Custom CNN - Smallest size, fastest inference\")"
      ],
      "metadata": {
        "id": "compare_models"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Visualize Model Architecture"
      ],
      "metadata": {
        "id": "visualize_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Plot MobileNetV2 architecture\n",
        "print(\"\\nüìê MobileNetV2 Architecture Diagram\")\n",
        "try:\n",
        "    plot_model(\n",
        "        mobilenet_model, \n",
        "        to_file='/content/mobilenet_architecture.png',\n",
        "        show_shapes=True,\n",
        "        show_layer_names=True,\n",
        "        dpi=100\n",
        "    )\n",
        "    from IPython.display import Image, display\n",
        "    display(Image('/content/mobilenet_architecture.png'))\n",
        "except Exception as e:\n",
        "    print(f\"Could not generate diagram: {e}\")\n",
        "    print(\"(This requires graphviz to be installed)\")"
      ],
      "metadata": {
        "id": "visualize_arch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Select Final Model & Compile"
      ],
      "metadata": {
        "id": "select_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== SELECT YOUR MODEL HERE =====\n",
        "# Options: 'mobilenet', 'efficientnet', 'custom'\n",
        "\n",
        "SELECTED_MODEL = 'mobilenet'  # Change this to select different model\n",
        "\n",
        "# Get the selected model\n",
        "if SELECTED_MODEL == 'mobilenet':\n",
        "    final_model = mobilenet_model\n",
        "    model_name = 'PotatoDisease_MobileNetV2'\n",
        "elif SELECTED_MODEL == 'efficientnet':\n",
        "    final_model = efficientnet_model\n",
        "    model_name = 'PotatoDisease_EfficientNetB0'\n",
        "else:\n",
        "    final_model = custom_model\n",
        "    model_name = 'PotatoDisease_CustomCNN'\n",
        "\n",
        "print(f\"\\n‚úÖ Selected Model: {model_name}\")\n",
        "\n",
        "# Compile the model\n",
        "final_model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', \n",
        "             tf.keras.metrics.Precision(name='precision'),\n",
        "             tf.keras.metrics.Recall(name='recall')]\n",
        ")\n",
        "\n",
        "print(\"\\nüìã Model compiled with:\")\n",
        "print(f\"   ‚Ä¢ Optimizer: Adam (lr={LEARNING_RATE})\")\n",
        "print(f\"   ‚Ä¢ Loss: Categorical Crossentropy\")\n",
        "print(f\"   ‚Ä¢ Metrics: Accuracy, Precision, Recall\")"
      ],
      "metadata": {
        "id": "select_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Define Training Callbacks"
      ],
      "metadata": {
        "id": "callbacks_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_callbacks(model_save_path):\n",
        "    \"\"\"\n",
        "    Create training callbacks for:\n",
        "    - Early stopping to prevent overfitting\n",
        "    - Model checkpointing to save best weights\n",
        "    - Learning rate reduction on plateau\n",
        "    \"\"\"\n",
        "    callbacks = [\n",
        "        # Early stopping\n",
        "        EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=10,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        \n",
        "        # Save best model\n",
        "        ModelCheckpoint(\n",
        "            filepath=model_save_path,\n",
        "            monitor='val_accuracy',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=False,\n",
        "            verbose=1\n",
        "        ),\n",
        "        \n",
        "        # Reduce LR on plateau\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.2,\n",
        "            patience=5,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "    \n",
        "    return callbacks\n",
        "\n",
        "\n",
        "# Create callbacks\n",
        "model_save_path = os.path.join(MODEL_SAVE_DIR, f\"{model_name}_best.keras\")\n",
        "callbacks = create_callbacks(model_save_path)\n",
        "\n",
        "print(\"\\n‚úÖ Training callbacks configured:\")\n",
        "print(f\"   ‚Ä¢ EarlyStopping (patience=10)\")\n",
        "print(f\"   ‚Ä¢ ModelCheckpoint ‚Üí {model_save_path}\")\n",
        "print(f\"   ‚Ä¢ ReduceLROnPlateau (factor=0.2)\")"
      ],
      "metadata": {
        "id": "create_callbacks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Save Architecture Configuration"
      ],
      "metadata": {
        "id": "save_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_architecture_config(model, model_name, save_dir):\n",
        "    \"\"\"\n",
        "    Save model architecture configuration for documentation.\n",
        "    \"\"\"\n",
        "    # Convert numpy int64 to Python int for JSON serialization\n",
        "    total_params = int(model.count_params())\n",
        "    trainable_params = int(sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]))\n",
        "    num_layers = int(len(model.layers))\n",
        "    \n",
        "    config = {\n",
        "        'phase': 'Phase 5: Model Selection & Architecture Design',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'model_name': model_name,\n",
        "        'architecture': {\n",
        "            'input_shape': list(IMG_SHAPE),\n",
        "            'num_classes': int(NUM_CLASSES),\n",
        "            'class_names': CLASS_NAMES,\n",
        "            'total_params': total_params,\n",
        "            'trainable_params': trainable_params,\n",
        "            'layers': num_layers\n",
        "        },\n",
        "        'training_config': {\n",
        "            'optimizer': 'Adam',\n",
        "            'learning_rate': float(LEARNING_RATE),\n",
        "            'loss': 'categorical_crossentropy',\n",
        "            'batch_size': int(BATCH_SIZE),\n",
        "            'epochs': int(EPOCHS)\n",
        "        },\n",
        "        'callbacks': [\n",
        "            'EarlyStopping (patience=10)',\n",
        "            'ModelCheckpoint (best val_accuracy)',\n",
        "            'ReduceLROnPlateau (factor=0.2)'\n",
        "        ],\n",
        "        'regularization': [\n",
        "            'L2 regularization (0.01)',\n",
        "            'Dropout (0.3-0.5)',\n",
        "            'Batch Normalization'\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    # Save config\n",
        "    config_path = os.path.join(save_dir, 'architecture_config.json')\n",
        "    with open(config_path, 'w') as f:\n",
        "        json.dump(config, f, indent=2)\n",
        "    \n",
        "    # Save model architecture (JSON)\n",
        "    arch_path = os.path.join(save_dir, f'{model_name}_architecture.json')\n",
        "    with open(arch_path, 'w') as f:\n",
        "        f.write(model.to_json())\n",
        "    \n",
        "    return config\n",
        "\n",
        "\n",
        "# Save configuration\n",
        "arch_config = save_architecture_config(final_model, model_name, MODEL_SAVE_DIR)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìã ARCHITECTURE CONFIGURATION SAVED\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n‚úÖ Config saved to: {MODEL_SAVE_DIR}/architecture_config.json\")\n",
        "print(f\"‚úÖ Architecture saved to: {MODEL_SAVE_DIR}/{model_name}_architecture.json\")"
      ],
      "metadata": {
        "id": "save_config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Architecture Summary"
      ],
      "metadata": {
        "id": "summary_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get parameters as Python int for display\n",
        "total_p = int(final_model.count_params())\n",
        "trainable_p = int(sum([tf.keras.backend.count_params(w) for w in final_model.trainable_weights]))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìã PHASE 5 SUMMARY: Model Architecture Design\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\"\"\n",
        "üèÜ SELECTED MODEL: {model_name}\n",
        "\n",
        "üìê ARCHITECTURE:\n",
        "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "   ‚îÇ  Input Layer (224 √ó 224 √ó 3)                                ‚îÇ\n",
        "   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "   ‚îÇ  Preprocessing (Rescaling)                                  ‚îÇ\n",
        "   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "   ‚îÇ  MobileNetV2 Base (ImageNet pretrained)                     ‚îÇ\n",
        "   ‚îÇ  - Last 20 layers fine-tuned                                ‚îÇ\n",
        "   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "   ‚îÇ  Global Average Pooling 2D                                  ‚îÇ\n",
        "   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "   ‚îÇ  BatchNormalization                                         ‚îÇ\n",
        "   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "   ‚îÇ  Dense(256, ReLU) + L2 Regularization                       ‚îÇ\n",
        "   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "   ‚îÇ  Dropout(0.5)                                               ‚îÇ\n",
        "   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "   ‚îÇ  Dense(128, ReLU) + L2 Regularization                       ‚îÇ\n",
        "   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "   ‚îÇ  Dropout(0.3)                                               ‚îÇ\n",
        "   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "   ‚îÇ  Dense(3, Softmax) ‚Üí Output                                 ‚îÇ\n",
        "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "üìä PARAMETERS:\n",
        "   ‚Ä¢ Total: {total_p:,}\n",
        "   ‚Ä¢ Trainable: {trainable_p:,}\n",
        "\n",
        "üõ°Ô∏è REGULARIZATION:\n",
        "   ‚Ä¢ L2 weight decay (Œª=0.01)\n",
        "   ‚Ä¢ Dropout (0.3-0.5)\n",
        "   ‚Ä¢ Batch Normalization\n",
        "   ‚Ä¢ Early Stopping\n",
        "\n",
        "üìÇ OUTPUT CLASSES:\n",
        "   0 ‚Üí Early_Blight\n",
        "   1 ‚Üí Healthy  \n",
        "   2 ‚Üí Late_Blight\n",
        "\n",
        "‚úÖ Model is ready for training in Phase 6!\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "architecture_summary"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Phase 5 Complete!\n",
        "\n",
        "**Selected Architecture:** MobileNetV2 with custom classification head\n",
        "\n",
        "**Key Design Decisions:**\n",
        "- ‚úÖ Transfer learning from ImageNet\n",
        "- ‚úÖ Fine-tuning last 20 layers\n",
        "- ‚úÖ Global Average Pooling (reduces overfitting)\n",
        "- ‚úÖ Heavy dropout regularization\n",
        "- ‚úÖ L2 weight regularization\n",
        "- ‚úÖ Mobile-deployment ready\n",
        "\n",
        "**Saved Files:**\n",
        "```\n",
        "/content/drive/MyDrive/DrukFarm/models/\n",
        "‚îú‚îÄ‚îÄ architecture_config.json\n",
        "‚îî‚îÄ‚îÄ PotatoDisease_MobileNetV2_architecture.json\n",
        "```\n",
        "\n",
        "**Next Steps:**\n",
        "- Phase 6: Model Training & Evaluation"
      ],
      "metadata": {
        "id": "conclusion"
      }
    }
  ]
}
