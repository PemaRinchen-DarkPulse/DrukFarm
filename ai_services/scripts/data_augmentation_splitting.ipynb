{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ¥” Phase 4: Data Augmentation & Dataset Splitting\n",
        "\n",
        "This notebook augments and splits the preprocessed potato disease dataset for model training.\n",
        "\n",
        "**Features:**\n",
        "- Stratified split into train/validation/test sets (70/20/10)\n",
        "- Realistic data augmentation for training set\n",
        "- Maintains class balance across all subsets\n",
        "- Preserves original images in validation/test sets\n",
        "- Generates comprehensive split statistics"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Mount Google Drive"
      ],
      "metadata": {
        "id": "mount_header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_drive"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "MOUNT_PATH = '/content/drive'\n",
        "\n",
        "def mount_drive():\n",
        "    \"\"\"Mount Google Drive with automatic error handling.\"\"\"\n",
        "    if os.path.exists(os.path.join(MOUNT_PATH, 'MyDrive')):\n",
        "        print('âœ… Google Drive is already mounted!')\n",
        "        return True\n",
        "    \n",
        "    if os.path.exists(MOUNT_PATH):\n",
        "        print('ðŸ”„ Clearing existing mount point...')\n",
        "        try:\n",
        "            drive.flush_and_unmount()\n",
        "        except:\n",
        "            pass\n",
        "        if os.path.exists(MOUNT_PATH):\n",
        "            try:\n",
        "                shutil.rmtree(MOUNT_PATH)\n",
        "            except:\n",
        "                pass\n",
        "    \n",
        "    try:\n",
        "        drive.mount(MOUNT_PATH)\n",
        "        print('âœ… Google Drive mounted successfully!')\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f'âŒ Mount failed: {e}')\n",
        "        print('ðŸ”§ Try: Runtime â†’ Restart runtime, then run again')\n",
        "        return False\n",
        "\n",
        "mount_drive()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Install Dependencies & Configuration"
      ],
      "metadata": {
        "id": "config_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q pillow opencv-python-headless albumentations tqdm scikit-learn\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "print(\"âœ… Dependencies loaded!\")\n",
        "print(f\"ðŸŽ² Random seed: {RANDOM_SEED}\")\n",
        "print(f\"ðŸ“¦ Albumentations version: {A.__version__}\")"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== CONFIGURATION =====\n",
        "\n",
        "# Source: Preprocessed dataset from Phase 3\n",
        "SOURCE_DIR = \"/content/drive/MyDrive/DrukFarm/data/preprocessed_potato_dataset\"\n",
        "\n",
        "# Output: Final split and augmented dataset\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/DrukFarm/data/final_potato_dataset\"\n",
        "\n",
        "# Split ratios\n",
        "TRAIN_RATIO = 0.70  # 70% for training\n",
        "VAL_RATIO = 0.20    # 20% for validation\n",
        "TEST_RATIO = 0.10   # 10% for testing\n",
        "\n",
        "# Augmentation settings\n",
        "AUGMENT_TRAINING = True          # Apply augmentation to training set\n",
        "AUGMENTATION_FACTOR = 3          # Number of augmented versions per original image\n",
        "TARGET_SIZE = (224, 224)         # Image size (should match preprocessing)\n",
        "\n",
        "# Valid extensions\n",
        "VALID_EXTENSIONS = {'.jpg', '.jpeg', '.png'}\n",
        "\n",
        "print(\"âœ… Configuration loaded!\")\n",
        "print(f\"\\nðŸ“ Source: {SOURCE_DIR}\")\n",
        "print(f\"ðŸ“‚ Output: {OUTPUT_DIR}\")\n",
        "print(f\"\\nðŸ“Š Split ratios:\")\n",
        "print(f\"   â€¢ Training: {TRAIN_RATIO*100:.0f}%\")\n",
        "print(f\"   â€¢ Validation: {VAL_RATIO*100:.0f}%\")\n",
        "print(f\"   â€¢ Testing: {TEST_RATIO*100:.0f}%\")\n",
        "print(f\"\\nðŸ”„ Augmentation factor: {AUGMENTATION_FACTOR}x (training only)\")"
      ],
      "metadata": {
        "id": "configuration"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Define Augmentation Pipeline"
      ],
      "metadata": {
        "id": "augmentation_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_augmentation_pipeline():\n",
        "    \"\"\"\n",
        "    Create a robust augmentation pipeline using Albumentations.\n",
        "    These transformations simulate real-world variations in leaf images.\n",
        "    Compatible with albumentations v1.4+\n",
        "    \"\"\"\n",
        "    transform = A.Compose([\n",
        "        # Geometric transformations\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.3),\n",
        "        A.Rotate(limit=30, p=0.5, border_mode=cv2.BORDER_REFLECT),\n",
        "        A.Affine(\n",
        "            scale=(0.9, 1.1),\n",
        "            translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
        "            rotate=(-15, 15),\n",
        "            shear=(-5, 5),\n",
        "            p=0.5,\n",
        "            mode=cv2.BORDER_REFLECT\n",
        "        ),\n",
        "        \n",
        "        # Random crop and resize (compatible syntax)\n",
        "        A.RandomScale(scale_limit=0.15, p=0.3),\n",
        "        A.PadIfNeeded(\n",
        "            min_height=TARGET_SIZE[0],\n",
        "            min_width=TARGET_SIZE[1],\n",
        "            border_mode=cv2.BORDER_REFLECT,\n",
        "            p=1.0\n",
        "        ),\n",
        "        A.RandomCrop(\n",
        "            height=TARGET_SIZE[0],\n",
        "            width=TARGET_SIZE[1],\n",
        "            p=0.5\n",
        "        ),\n",
        "        \n",
        "        # Color/lighting transformations (preserve disease characteristics)\n",
        "        A.OneOf([\n",
        "            A.RandomBrightnessContrast(\n",
        "                brightness_limit=0.2,\n",
        "                contrast_limit=0.2,\n",
        "                p=1\n",
        "            ),\n",
        "            A.ColorJitter(\n",
        "                brightness=0.15,\n",
        "                contrast=0.15,\n",
        "                saturation=0.1,\n",
        "                hue=0.05,\n",
        "                p=1\n",
        "            ),\n",
        "        ], p=0.5),\n",
        "        \n",
        "        # Slight blur to simulate focus variations\n",
        "        A.OneOf([\n",
        "            A.GaussianBlur(blur_limit=(3, 5), p=1),\n",
        "            A.MotionBlur(blur_limit=3, p=1),\n",
        "        ], p=0.2),\n",
        "        \n",
        "        # Add slight noise (simulates camera sensor noise)\n",
        "        A.GaussNoise(var_limit=(5, 20), p=0.2),\n",
        "        \n",
        "        # Ensure output size is correct\n",
        "        A.Resize(height=TARGET_SIZE[0], width=TARGET_SIZE[1]),\n",
        "    ])\n",
        "    \n",
        "    return transform\n",
        "\n",
        "\n",
        "# Create pipeline\n",
        "augmentation_pipeline = create_augmentation_pipeline()\n",
        "print(\"âœ… Augmentation pipeline created!\")\n",
        "print(\"\\nðŸ“‹ Augmentation techniques:\")\n",
        "print(\"   â€¢ Horizontal/Vertical flip\")\n",
        "print(\"   â€¢ Rotation (Â±30Â°)\")\n",
        "print(\"   â€¢ Affine transforms (scale, translate, shear)\")\n",
        "print(\"   â€¢ Random crop & scale\")\n",
        "print(\"   â€¢ Brightness/contrast adjustment\")\n",
        "print(\"   â€¢ Color jitter\")\n",
        "print(\"   â€¢ Gaussian blur/noise\")"
      ],
      "metadata": {
        "id": "augmentation_pipeline"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Scan Source Dataset"
      ],
      "metadata": {
        "id": "scan_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scan_dataset(source_dir: str) -> dict:\n",
        "    \"\"\"\n",
        "    Scan source dataset and collect all image paths by class.\n",
        "    \"\"\"\n",
        "    dataset = {}\n",
        "    \n",
        "    if not os.path.exists(source_dir):\n",
        "        print(f\"âŒ Source directory not found: {source_dir}\")\n",
        "        return dataset\n",
        "    \n",
        "    class_dirs = [d for d in os.listdir(source_dir) \n",
        "                  if os.path.isdir(os.path.join(source_dir, d))]\n",
        "    \n",
        "    print(f\"ðŸ“ Found {len(class_dirs)} classes\\n\")\n",
        "    \n",
        "    total_images = 0\n",
        "    for class_name in sorted(class_dirs):\n",
        "        class_path = os.path.join(source_dir, class_name)\n",
        "        \n",
        "        # Get all valid images\n",
        "        images = [\n",
        "            os.path.join(class_path, f)\n",
        "            for f in os.listdir(class_path)\n",
        "            if Path(f).suffix.lower() in VALID_EXTENSIONS\n",
        "        ]\n",
        "        \n",
        "        dataset[class_name] = images\n",
        "        total_images += len(images)\n",
        "        print(f\"   ðŸ·ï¸ {class_name}: {len(images)} images\")\n",
        "    \n",
        "    print(f\"\\nðŸ“Š Total images: {total_images}\")\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# Scan dataset\n",
        "print(\"ðŸ” Scanning source dataset...\\n\")\n",
        "source_dataset = scan_dataset(SOURCE_DIR)"
      ],
      "metadata": {
        "id": "scan_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Stratified Dataset Split"
      ],
      "metadata": {
        "id": "split_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stratified_split(dataset: dict, train_ratio: float, val_ratio: float, \n",
        "                     test_ratio: float, seed: int = 42) -> dict:\n",
        "    \"\"\"\n",
        "    Perform stratified split maintaining class balance.\n",
        "    Returns dict with train/val/test splits per class.\n",
        "    \"\"\"\n",
        "    splits = {\n",
        "        'train': {},\n",
        "        'validation': {},\n",
        "        'test': {}\n",
        "    }\n",
        "    \n",
        "    print(\"ðŸ“Š Performing stratified split...\\n\")\n",
        "    \n",
        "    for class_name, images in dataset.items():\n",
        "        # Shuffle images\n",
        "        shuffled = images.copy()\n",
        "        random.Random(seed).shuffle(shuffled)\n",
        "        \n",
        "        n_total = len(shuffled)\n",
        "        n_test = max(1, int(n_total * test_ratio))\n",
        "        n_val = max(1, int(n_total * val_ratio))\n",
        "        n_train = n_total - n_val - n_test\n",
        "        \n",
        "        # Split\n",
        "        splits['test'][class_name] = shuffled[:n_test]\n",
        "        splits['validation'][class_name] = shuffled[n_test:n_test + n_val]\n",
        "        splits['train'][class_name] = shuffled[n_test + n_val:]\n",
        "        \n",
        "        print(f\"   ðŸ·ï¸ {class_name}:\")\n",
        "        print(f\"      Train: {len(splits['train'][class_name])} | \"\n",
        "              f\"Val: {len(splits['validation'][class_name])} | \"\n",
        "              f\"Test: {len(splits['test'][class_name])}\")\n",
        "    \n",
        "    # Summary\n",
        "    total_train = sum(len(v) for v in splits['train'].values())\n",
        "    total_val = sum(len(v) for v in splits['validation'].values())\n",
        "    total_test = sum(len(v) for v in splits['test'].values())\n",
        "    total = total_train + total_val + total_test\n",
        "    \n",
        "    print(f\"\\nðŸ“Š SPLIT SUMMARY:\")\n",
        "    print(f\"   â€¢ Training: {total_train} images ({total_train/total*100:.1f}%)\")\n",
        "    print(f\"   â€¢ Validation: {total_val} images ({total_val/total*100:.1f}%)\")\n",
        "    print(f\"   â€¢ Testing: {total_test} images ({total_test/total*100:.1f}%)\")\n",
        "    \n",
        "    return splits\n",
        "\n",
        "\n",
        "# Perform split\n",
        "dataset_splits = stratified_split(\n",
        "    source_dataset, \n",
        "    TRAIN_RATIO, \n",
        "    VAL_RATIO, \n",
        "    TEST_RATIO,\n",
        "    seed=RANDOM_SEED\n",
        ")"
      ],
      "metadata": {
        "id": "stratified_split"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Create Output Directory Structure"
      ],
      "metadata": {
        "id": "structure_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_output_structure(output_dir: str, classes: list) -> None:\n",
        "    \"\"\"\n",
        "    Create the output directory structure.\n",
        "    \"\"\"\n",
        "    # Remove existing output directory if exists\n",
        "    if os.path.exists(output_dir):\n",
        "        print(f\"âš ï¸ Removing existing output directory...\")\n",
        "        shutil.rmtree(output_dir)\n",
        "    \n",
        "    # Create structure\n",
        "    subsets = ['train', 'validation', 'test']\n",
        "    \n",
        "    for subset in subsets:\n",
        "        for class_name in classes:\n",
        "            dir_path = os.path.join(output_dir, subset, class_name)\n",
        "            os.makedirs(dir_path, exist_ok=True)\n",
        "    \n",
        "    print(f\"âœ… Created output structure at: {output_dir}\")\n",
        "    print(f\"\\nðŸ“‚ Structure:\")\n",
        "    print(f\"   {os.path.basename(output_dir)}/\")\n",
        "    for subset in subsets:\n",
        "        print(f\"   â”œâ”€â”€ {subset}/\")\n",
        "        for i, class_name in enumerate(sorted(classes)):\n",
        "            connector = \"â””â”€â”€\" if i == len(classes) - 1 else \"â”œâ”€â”€\"\n",
        "            print(f\"   â”‚   {connector} {class_name}/\")\n",
        "\n",
        "\n",
        "# Create structure\n",
        "classes = list(source_dataset.keys())\n",
        "create_output_structure(OUTPUT_DIR, classes)"
      ],
      "metadata": {
        "id": "create_structure"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Copy & Augment Images"
      ],
      "metadata": {
        "id": "copy_augment_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_and_save(image_path: str, output_dir: str, class_name: str,\n",
        "                      base_name: str, aug_pipeline, n_augments: int) -> int:\n",
        "    \"\"\"\n",
        "    Apply augmentation and save augmented images.\n",
        "    Returns number of images saved.\n",
        "    \"\"\"\n",
        "    saved = 0\n",
        "    \n",
        "    try:\n",
        "        # Load image\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            return 0\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        for i in range(n_augments):\n",
        "            # Apply augmentation\n",
        "            augmented = aug_pipeline(image=image)\n",
        "            aug_image = augmented['image']\n",
        "            \n",
        "            # Convert back to BGR for saving\n",
        "            aug_image_bgr = cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR)\n",
        "            \n",
        "            # Save augmented image\n",
        "            aug_filename = f\"{base_name}_aug{i+1}.jpg\"\n",
        "            output_path = os.path.join(output_dir, class_name, aug_filename)\n",
        "            cv2.imwrite(output_path, aug_image_bgr, [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
        "            saved += 1\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"\\n   âš ï¸ Error augmenting {base_name}: {e}\")\n",
        "    \n",
        "    return saved\n",
        "\n",
        "\n",
        "def copy_images(splits: dict, output_dir: str, aug_pipeline, \n",
        "                augment_train: bool, aug_factor: int) -> dict:\n",
        "    \"\"\"\n",
        "    Copy images to output directory and apply augmentation to training set.\n",
        "    \"\"\"\n",
        "    stats = {\n",
        "        'train': {'original': 0, 'augmented': 0, 'total': 0, 'by_class': {}},\n",
        "        'validation': {'original': 0, 'total': 0, 'by_class': {}},\n",
        "        'test': {'original': 0, 'total': 0, 'by_class': {}}\n",
        "    }\n",
        "    \n",
        "    for subset_name, subset_data in splits.items():\n",
        "        print(f\"\\nðŸ“ Processing {subset_name} set...\")\n",
        "        subset_dir = os.path.join(output_dir, subset_name)\n",
        "        \n",
        "        for class_name, image_paths in subset_data.items():\n",
        "            class_original = 0\n",
        "            class_augmented = 0\n",
        "            \n",
        "            for img_path in tqdm(image_paths, desc=f\"   {class_name}\", leave=False):\n",
        "                base_name = Path(img_path).stem\n",
        "                \n",
        "                # Copy original image\n",
        "                dest_path = os.path.join(subset_dir, class_name, f\"{base_name}.jpg\")\n",
        "                shutil.copy2(img_path, dest_path)\n",
        "                class_original += 1\n",
        "                \n",
        "                # Apply augmentation only to training set\n",
        "                if subset_name == 'train' and augment_train:\n",
        "                    n_saved = augment_and_save(\n",
        "                        img_path, subset_dir, class_name,\n",
        "                        base_name, aug_pipeline, aug_factor\n",
        "                    )\n",
        "                    class_augmented += n_saved\n",
        "            \n",
        "            # Update stats\n",
        "            stats[subset_name]['original'] += class_original\n",
        "            stats[subset_name]['by_class'][class_name] = {\n",
        "                'original': class_original,\n",
        "                'augmented': class_augmented if subset_name == 'train' else 0,\n",
        "                'total': class_original + (class_augmented if subset_name == 'train' else 0)\n",
        "            }\n",
        "            \n",
        "            if subset_name == 'train':\n",
        "                stats['train']['augmented'] += class_augmented\n",
        "            \n",
        "            print(f\"   âœ… {class_name}: {class_original} original\" + \n",
        "                  (f\" + {class_augmented} augmented\" if subset_name == 'train' and augment_train else \"\"))\n",
        "        \n",
        "        # Calculate totals\n",
        "        stats[subset_name]['total'] = stats[subset_name]['original']\n",
        "        if subset_name == 'train':\n",
        "            stats['train']['total'] += stats['train']['augmented']\n",
        "    \n",
        "    return stats\n",
        "\n",
        "\n",
        "# Process dataset\n",
        "print(\"ðŸš€ STARTING DATASET PROCESSING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "processing_stats = copy_images(\n",
        "    dataset_splits,\n",
        "    OUTPUT_DIR,\n",
        "    augmentation_pipeline,\n",
        "    AUGMENT_TRAINING,\n",
        "    AUGMENTATION_FACTOR\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"âœ… PROCESSING COMPLETED!\")"
      ],
      "metadata": {
        "id": "copy_augment"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Generate Final Report"
      ],
      "metadata": {
        "id": "report_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_report(stats: dict, output_dir: str) -> dict:\n",
        "    \"\"\"\n",
        "    Generate comprehensive final report.\n",
        "    \"\"\"\n",
        "    report = {\n",
        "        'phase': 'Phase 4: Data Augmentation & Dataset Splitting',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'configuration': {\n",
        "            'source_dir': SOURCE_DIR,\n",
        "            'output_dir': OUTPUT_DIR,\n",
        "            'split_ratios': {\n",
        "                'train': TRAIN_RATIO,\n",
        "                'validation': VAL_RATIO,\n",
        "                'test': TEST_RATIO\n",
        "            },\n",
        "            'augmentation': {\n",
        "                'enabled': AUGMENT_TRAINING,\n",
        "                'factor': AUGMENTATION_FACTOR,\n",
        "                'target_size': TARGET_SIZE\n",
        "            },\n",
        "            'random_seed': RANDOM_SEED\n",
        "        },\n",
        "        'statistics': stats\n",
        "    }\n",
        "    \n",
        "    # Save report\n",
        "    report_path = os.path.join(output_dir, 'dataset_report.json')\n",
        "    with open(report_path, 'w') as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "    \n",
        "    return report\n",
        "\n",
        "\n",
        "# Generate report\n",
        "final_report = generate_report(processing_stats, OUTPUT_DIR)\n",
        "\n",
        "# Display summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ðŸ“‹ FINAL REPORT: Phase 4 Complete\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nðŸ“… Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "print(f\"\\nðŸ“Š DATASET STATISTICS:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Training set\n",
        "print(f\"\\nðŸ‹ï¸ TRAINING SET:\")\n",
        "print(f\"   Original images: {processing_stats['train']['original']}\")\n",
        "print(f\"   Augmented images: {processing_stats['train']['augmented']}\")\n",
        "print(f\"   Total: {processing_stats['train']['total']}\")\n",
        "for class_name, class_stats in sorted(processing_stats['train']['by_class'].items()):\n",
        "    print(f\"   â””â”€ {class_name}: {class_stats['total']} ({class_stats['original']} + {class_stats['augmented']} aug)\")\n",
        "\n",
        "# Validation set\n",
        "print(f\"\\nðŸ“Š VALIDATION SET:\")\n",
        "print(f\"   Total: {processing_stats['validation']['original']}\")\n",
        "for class_name, class_stats in sorted(processing_stats['validation']['by_class'].items()):\n",
        "    print(f\"   â””â”€ {class_name}: {class_stats['original']}\")\n",
        "\n",
        "# Test set\n",
        "print(f\"\\nðŸ§ª TEST SET:\")\n",
        "print(f\"   Total: {processing_stats['test']['original']}\")\n",
        "for class_name, class_stats in sorted(processing_stats['test']['by_class'].items()):\n",
        "    print(f\"   â””â”€ {class_name}: {class_stats['original']}\")\n",
        "\n",
        "# Grand total\n",
        "grand_total = (processing_stats['train']['total'] + \n",
        "               processing_stats['validation']['original'] + \n",
        "               processing_stats['test']['original'])\n",
        "print(f\"\\nðŸ“ GRAND TOTAL: {grand_total} images\")\n",
        "\n",
        "print(f\"\\nðŸ’¾ Report saved to: {OUTPUT_DIR}/dataset_report.json\")"
      ],
      "metadata": {
        "id": "generate_report"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Verify Output Dataset"
      ],
      "metadata": {
        "id": "verify_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_dataset(output_dir: str) -> None:\n",
        "    \"\"\"\n",
        "    Verify the final dataset structure and count images.\n",
        "    \"\"\"\n",
        "    print(\"\\nðŸ” VERIFICATION\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    if not os.path.exists(output_dir):\n",
        "        print(\"âŒ Output directory does not exist!\")\n",
        "        return\n",
        "    \n",
        "    subsets = ['train', 'validation', 'test']\n",
        "    \n",
        "    for subset in subsets:\n",
        "        subset_path = os.path.join(output_dir, subset)\n",
        "        if not os.path.exists(subset_path):\n",
        "            print(f\"âŒ Missing: {subset}/\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"\\nðŸ“‚ {subset}/\")\n",
        "        total = 0\n",
        "        for class_name in sorted(os.listdir(subset_path)):\n",
        "            class_path = os.path.join(subset_path, class_name)\n",
        "            if os.path.isdir(class_path):\n",
        "                count = len([f for f in os.listdir(class_path) \n",
        "                            if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "                total += count\n",
        "                print(f\"   â”œâ”€â”€ {class_name}/: {count} images\")\n",
        "        print(f\"   â””â”€â”€ Total: {total} images\")\n",
        "    \n",
        "    print(\"\\nâœ… Verification complete!\")\n",
        "\n",
        "\n",
        "# Verify\n",
        "verify_dataset(OUTPUT_DIR)"
      ],
      "metadata": {
        "id": "verify_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Preview Augmented Samples"
      ],
      "metadata": {
        "id": "preview_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def preview_augmented_samples(output_dir: str, samples_per_class: int = 4) -> None:\n",
        "    \"\"\"\n",
        "    Display original and augmented samples from training set.\n",
        "    \"\"\"\n",
        "    train_dir = os.path.join(output_dir, 'train')\n",
        "    classes = sorted([d for d in os.listdir(train_dir) \n",
        "                      if os.path.isdir(os.path.join(train_dir, d))])\n",
        "    \n",
        "    if not classes:\n",
        "        print(\"No classes found!\")\n",
        "        return\n",
        "    \n",
        "    fig, axes = plt.subplots(len(classes), samples_per_class, \n",
        "                             figsize=(14, 3.5 * len(classes)))\n",
        "    \n",
        "    if len(classes) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for i, class_name in enumerate(classes):\n",
        "        class_path = os.path.join(train_dir, class_name)\n",
        "        \n",
        "        # Get mix of original and augmented\n",
        "        all_images = [f for f in os.listdir(class_path) if f.endswith('.jpg')]\n",
        "        originals = [f for f in all_images if '_aug' not in f][:2]\n",
        "        augmented = [f for f in all_images if '_aug' in f][:2]\n",
        "        samples = originals + augmented\n",
        "        \n",
        "        for j, img_name in enumerate(samples[:samples_per_class]):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "            img = Image.open(img_path)\n",
        "            \n",
        "            ax = axes[i][j] if len(classes) > 1 else axes[j]\n",
        "            ax.imshow(img)\n",
        "            \n",
        "            label_type = \"AUG\" if \"_aug\" in img_name else \"ORIG\"\n",
        "            ax.set_title(f\"{class_name}\\n[{label_type}]\", fontsize=9)\n",
        "            ax.axis('off')\n",
        "        \n",
        "        # Fill empty slots\n",
        "        for j in range(len(samples), samples_per_class):\n",
        "            ax = axes[i][j] if len(classes) > 1 else axes[j]\n",
        "            ax.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.suptitle(\"Training Set Samples (Original vs Augmented)\", fontsize=14, y=1.02)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Preview\n",
        "preview_augmented_samples(OUTPUT_DIR)"
      ],
      "metadata": {
        "id": "preview_samples"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Class Distribution Visualization"
      ],
      "metadata": {
        "id": "visualization_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_distribution(stats: dict) -> None:\n",
        "    \"\"\"\n",
        "    Visualize class distribution across train/val/test sets.\n",
        "    \"\"\"\n",
        "    classes = list(stats['train']['by_class'].keys())\n",
        "    \n",
        "    train_counts = [stats['train']['by_class'][c]['total'] for c in classes]\n",
        "    val_counts = [stats['validation']['by_class'][c]['total'] for c in classes]\n",
        "    test_counts = [stats['test']['by_class'][c]['total'] for c in classes]\n",
        "    \n",
        "    x = np.arange(len(classes))\n",
        "    width = 0.25\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Bar chart\n",
        "    bars1 = ax1.bar(x - width, train_counts, width, label='Train', color='#4CAF50')\n",
        "    bars2 = ax1.bar(x, val_counts, width, label='Validation', color='#2196F3')\n",
        "    bars3 = ax1.bar(x + width, test_counts, width, label='Test', color='#FF9800')\n",
        "    \n",
        "    ax1.set_xlabel('Disease Class')\n",
        "    ax1.set_ylabel('Number of Images')\n",
        "    ax1.set_title('Class Distribution Across Subsets')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(classes, rotation=15)\n",
        "    ax1.legend()\n",
        "    ax1.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bars in [bars1, bars2, bars3]:\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax1.annotate(f'{int(height)}',\n",
        "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                        xytext=(0, 3), textcoords=\"offset points\",\n",
        "                        ha='center', va='bottom', fontsize=8)\n",
        "    \n",
        "    # Pie chart for overall split\n",
        "    sizes = [\n",
        "        stats['train']['total'],\n",
        "        stats['validation']['original'],\n",
        "        stats['test']['original']\n",
        "    ]\n",
        "    labels = ['Train', 'Validation', 'Test']\n",
        "    colors = ['#4CAF50', '#2196F3', '#FF9800']\n",
        "    explode = (0.05, 0, 0)\n",
        "    \n",
        "    ax2.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
        "            shadow=True, startangle=90)\n",
        "    ax2.set_title('Overall Dataset Split')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Visualize\n",
        "visualize_distribution(processing_stats)"
      ],
      "metadata": {
        "id": "visualize_distribution"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## âœ… Phase 4 Complete!\n",
        "\n",
        "The augmented and split dataset is ready at:\n",
        "```\n",
        "/content/drive/MyDrive/DrukFarm/data/final_potato_dataset/\n",
        "â”œâ”€â”€ train/\n",
        "â”‚   â”œâ”€â”€ Early_Blight/   (original + 3x augmented)\n",
        "â”‚   â”œâ”€â”€ Late_Blight/    (original + 3x augmented)\n",
        "â”‚   â””â”€â”€ Healthy/        (original + 3x augmented)\n",
        "â”œâ”€â”€ validation/\n",
        "â”‚   â”œâ”€â”€ Early_Blight/   (original only)\n",
        "â”‚   â”œâ”€â”€ Late_Blight/    (original only)\n",
        "â”‚   â””â”€â”€ Healthy/        (original only)\n",
        "â””â”€â”€ test/\n",
        "    â”œâ”€â”€ Early_Blight/   (original only)\n",
        "    â”œâ”€â”€ Late_Blight/    (original only)\n",
        "    â””â”€â”€ Healthy/        (original only)\n",
        "```\n",
        "\n",
        "**Key Achievements:**\n",
        "- âœ… Stratified 70/20/10 split\n",
        "- âœ… Class balance maintained\n",
        "- âœ… Training set augmented 3x\n",
        "- âœ… No data leakage between sets\n",
        "- âœ… Reproducible with seed=42\n",
        "\n",
        "**Next Steps:**\n",
        "- Phase 5: Model Training"
      ],
      "metadata": {
        "id": "conclusion"
      }
    }
  ]
}
