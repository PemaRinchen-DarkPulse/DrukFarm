{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ü•î Phase 6: Model Training & Hyperparameter Tuning\n",
        "\n",
        "This notebook trains and optimizes the potato disease classification model.\n",
        "\n",
        "**Features:**\n",
        "- Model training with real-time monitoring\n",
        "- Hyperparameter tuning experiments\n",
        "- Training visualization (loss/accuracy curves)\n",
        "- Best model checkpointing\n",
        "- Training report generation"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Mount Google Drive & Setup"
      ],
      "metadata": {
        "id": "mount_header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_drive"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "MOUNT_PATH = '/content/drive'\n",
        "\n",
        "def mount_drive():\n",
        "    if os.path.exists(os.path.join(MOUNT_PATH, 'MyDrive')):\n",
        "        print('‚úÖ Google Drive is already mounted!')\n",
        "        return True\n",
        "    if os.path.exists(MOUNT_PATH):\n",
        "        try:\n",
        "            drive.flush_and_unmount()\n",
        "        except:\n",
        "            pass\n",
        "        if os.path.exists(MOUNT_PATH):\n",
        "            try:\n",
        "                shutil.rmtree(MOUNT_PATH)\n",
        "            except:\n",
        "                pass\n",
        "    try:\n",
        "        drive.mount(MOUNT_PATH)\n",
        "        print('‚úÖ Google Drive mounted successfully!')\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f'‚ùå Mount failed: {e}')\n",
        "        return False\n",
        "\n",
        "mount_drive()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and import dependencies\n",
        "!pip install -q tensorflow keras matplotlib seaborn scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.callbacks import (\n",
        "    EarlyStopping, \n",
        "    ModelCheckpoint, \n",
        "    ReduceLROnPlateau,\n",
        "    TensorBoard,\n",
        "    CSVLogger\n",
        ")\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(f\"‚úÖ TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Check GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"üöÄ GPU detected: {gpus[0].name}\")\n",
        "    # Enable memory growth\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected, training will be slow\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Configuration"
      ],
      "metadata": {
        "id": "config_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== CONFIGURATION =====\n",
        "\n",
        "# Paths\n",
        "DATASET_DIR = \"/content/drive/MyDrive/DrukFarm/data/final_potato_dataset\"\n",
        "MODEL_SAVE_DIR = \"/content/drive/MyDrive/DrukFarm/models\"\n",
        "LOGS_DIR = \"/content/drive/MyDrive/DrukFarm/training_logs\"\n",
        "\n",
        "# Dataset paths\n",
        "TRAIN_DIR = os.path.join(DATASET_DIR, 'train')\n",
        "VAL_DIR = os.path.join(DATASET_DIR, 'validation')\n",
        "TEST_DIR = os.path.join(DATASET_DIR, 'test')\n",
        "\n",
        "# Model parameters\n",
        "IMG_SIZE = (224, 224)\n",
        "IMG_SHAPE = (224, 224, 3)\n",
        "NUM_CLASSES = 3\n",
        "CLASS_NAMES = ['Early_Blight', 'Healthy', 'Late_Blight']\n",
        "\n",
        "# Training hyperparameters (initial values)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.0001\n",
        "EPOCHS = 50\n",
        "FINE_TUNE_LAYERS = 20\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(LOGS_DIR, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Configuration loaded!\")\n",
        "print(f\"\\nüìÅ Dataset: {DATASET_DIR}\")\n",
        "print(f\"üìÇ Models: {MODEL_SAVE_DIR}\")\n",
        "print(f\"üìä Logs: {LOGS_DIR}\")\n",
        "print(f\"\\nüîß Hyperparameters:\")\n",
        "print(f\"   ‚Ä¢ Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   ‚Ä¢ Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"   ‚Ä¢ Epochs: {EPOCHS}\")\n",
        "print(f\"   ‚Ä¢ Fine-tune layers: {FINE_TUNE_LAYERS}\")"
      ],
      "metadata": {
        "id": "configuration"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Load Dataset"
      ],
      "metadata": {
        "id": "load_data_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_generators(train_dir, val_dir, test_dir, img_size, batch_size):\n",
        "    \"\"\"\n",
        "    Create data generators for training, validation, and testing.\n",
        "    \"\"\"\n",
        "    # Training generator with augmentation\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        zoom_range=0.1,\n",
        "        fill_mode='reflect'\n",
        "    )\n",
        "    \n",
        "    # Validation and test generators (no augmentation)\n",
        "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "    # Create generators\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True,\n",
        "        seed=SEED\n",
        "    )\n",
        "    \n",
        "    val_generator = val_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    return train_generator, val_generator, test_generator\n",
        "\n",
        "\n",
        "# Create data generators\n",
        "print(\"üìÇ Loading dataset...\\n\")\n",
        "train_gen, val_gen, test_gen = create_data_generators(\n",
        "    TRAIN_DIR, VAL_DIR, TEST_DIR, IMG_SIZE, BATCH_SIZE\n",
        ")\n",
        "\n",
        "print(f\"\\nüìä Dataset Summary:\")\n",
        "print(f\"   ‚Ä¢ Training samples: {train_gen.samples}\")\n",
        "print(f\"   ‚Ä¢ Validation samples: {val_gen.samples}\")\n",
        "print(f\"   ‚Ä¢ Test samples: {test_gen.samples}\")\n",
        "print(f\"   ‚Ä¢ Classes: {list(train_gen.class_indices.keys())}\")"
      ],
      "metadata": {
        "id": "load_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Build Model"
      ],
      "metadata": {
        "id": "build_model_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, num_classes, learning_rate, fine_tune_layers=20):\n",
        "    \"\"\"\n",
        "    Build MobileNetV2-based model for potato disease classification.\n",
        "    \"\"\"\n",
        "    # Load pre-trained base\n",
        "    base_model = MobileNetV2(\n",
        "        input_shape=input_shape,\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    \n",
        "    # Freeze early layers, fine-tune later layers\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers[:-fine_tune_layers]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # Build model\n",
        "    model = models.Sequential([\n",
        "        layers.InputLayer(input_shape=input_shape),\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(num_classes, activation='softmax', name='output')\n",
        "    ], name='PotatoDisease_MobileNetV2')\n",
        "    \n",
        "    # Compile\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall')\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "# Build model\n",
        "print(\"üî® Building model...\")\n",
        "model = build_model(IMG_SHAPE, NUM_CLASSES, LEARNING_RATE, FINE_TUNE_LAYERS)\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üì± Model Architecture\")\n",
        "print(\"=\" * 60)\n",
        "model.summary()\n",
        "\n",
        "print(f\"\\nüìä Total parameters: {int(model.count_params()):,}\")"
      ],
      "metadata": {
        "id": "build_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Define Training Callbacks"
      ],
      "metadata": {
        "id": "callbacks_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_callbacks(model_name, save_dir, logs_dir):\n",
        "    \"\"\"\n",
        "    Create comprehensive training callbacks.\n",
        "    \"\"\"\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    \n",
        "    callbacks = [\n",
        "        # Early stopping\n",
        "        EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=10,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        \n",
        "        # Save best model\n",
        "        ModelCheckpoint(\n",
        "            filepath=os.path.join(save_dir, f'{model_name}_best.keras'),\n",
        "            monitor='val_accuracy',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        \n",
        "        # Reduce LR on plateau\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.2,\n",
        "            patience=5,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        ),\n",
        "        \n",
        "        # CSV logging\n",
        "        CSVLogger(\n",
        "            os.path.join(logs_dir, f'training_log_{timestamp}.csv'),\n",
        "            separator=',',\n",
        "            append=False\n",
        "        )\n",
        "    ]\n",
        "    \n",
        "    return callbacks, timestamp\n",
        "\n",
        "\n",
        "# Create callbacks\n",
        "callbacks, timestamp = create_callbacks('PotatoDisease_MobileNetV2', MODEL_SAVE_DIR, LOGS_DIR)\n",
        "\n",
        "print(\"‚úÖ Training callbacks configured:\")\n",
        "print(f\"   ‚Ä¢ EarlyStopping (patience=10)\")\n",
        "print(f\"   ‚Ä¢ ModelCheckpoint (best val_accuracy)\")\n",
        "print(f\"   ‚Ä¢ ReduceLROnPlateau (factor=0.2)\")\n",
        "print(f\"   ‚Ä¢ CSVLogger ‚Üí training_log_{timestamp}.csv\")"
      ],
      "metadata": {
        "id": "create_callbacks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Train Model üöÄ"
      ],
      "metadata": {
        "id": "train_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üöÄ STARTING MODEL TRAINING\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nüìÖ Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"\\nüîß Training Configuration:\")\n",
        "print(f\"   ‚Ä¢ Epochs: {EPOCHS}\")\n",
        "print(f\"   ‚Ä¢ Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   ‚Ä¢ Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"   ‚Ä¢ Training samples: {train_gen.samples}\")\n",
        "print(f\"   ‚Ä¢ Validation samples: {val_gen.samples}\")\n",
        "print(\"\\n\" + \"-\" * 60)\n",
        "\n",
        "# Calculate steps\n",
        "steps_per_epoch = train_gen.samples // BATCH_SIZE\n",
        "validation_steps = val_gen.samples // BATCH_SIZE\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_gen,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Training time\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úÖ TRAINING COMPLETED!\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n‚è±Ô∏è Total training time: {training_time/60:.2f} minutes\")\n",
        "print(f\"üìÖ Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ],
      "metadata": {
        "id": "train_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Training Visualization"
      ],
      "metadata": {
        "id": "visualization_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "    \"\"\"\n",
        "    Plot training and validation metrics.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # Accuracy\n",
        "    axes[0, 0].plot(history.history['accuracy'], label='Training', linewidth=2)\n",
        "    axes[0, 0].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
        "    axes[0, 0].set_title('Model Accuracy', fontsize=14)\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Accuracy')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Loss\n",
        "    axes[0, 1].plot(history.history['loss'], label='Training', linewidth=2)\n",
        "    axes[0, 1].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
        "    axes[0, 1].set_title('Model Loss', fontsize=14)\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Loss')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Precision\n",
        "    if 'precision' in history.history:\n",
        "        axes[1, 0].plot(history.history['precision'], label='Training', linewidth=2)\n",
        "        axes[1, 0].plot(history.history['val_precision'], label='Validation', linewidth=2)\n",
        "        axes[1, 0].set_title('Model Precision', fontsize=14)\n",
        "        axes[1, 0].set_xlabel('Epoch')\n",
        "        axes[1, 0].set_ylabel('Precision')\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Recall\n",
        "    if 'recall' in history.history:\n",
        "        axes[1, 1].plot(history.history['recall'], label='Training', linewidth=2)\n",
        "        axes[1, 1].plot(history.history['val_recall'], label='Validation', linewidth=2)\n",
        "        axes[1, 1].set_title('Model Recall', fontsize=14)\n",
        "        axes[1, 1].set_xlabel('Epoch')\n",
        "        axes[1, 1].set_ylabel('Recall')\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.suptitle('Training History', fontsize=16, y=1.02)\n",
        "    plt.savefig(os.path.join(LOGS_DIR, f'training_curves_{timestamp}.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Plot training history\n",
        "plot_training_history(history)\n",
        "print(f\"\\nüíæ Training curves saved to: {LOGS_DIR}/training_curves_{timestamp}.png\")"
      ],
      "metadata": {
        "id": "plot_history"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Training Results Summary"
      ],
      "metadata": {
        "id": "results_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_metrics(history):\n",
        "    \"\"\"\n",
        "    Extract best metrics from training history.\n",
        "    \"\"\"\n",
        "    best_epoch = np.argmax(history.history['val_accuracy']) + 1\n",
        "    \n",
        "    metrics = {\n",
        "        'best_epoch': int(best_epoch),\n",
        "        'total_epochs': len(history.history['accuracy']),\n",
        "        'best_val_accuracy': float(max(history.history['val_accuracy'])),\n",
        "        'best_val_loss': float(min(history.history['val_loss'])),\n",
        "        'final_train_accuracy': float(history.history['accuracy'][-1]),\n",
        "        'final_val_accuracy': float(history.history['val_accuracy'][-1]),\n",
        "        'final_train_loss': float(history.history['loss'][-1]),\n",
        "        'final_val_loss': float(history.history['val_loss'][-1])\n",
        "    }\n",
        "    \n",
        "    if 'precision' in history.history:\n",
        "        metrics['best_val_precision'] = float(max(history.history['val_precision']))\n",
        "    if 'recall' in history.history:\n",
        "        metrics['best_val_recall'] = float(max(history.history['val_recall']))\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "\n",
        "# Get best metrics\n",
        "best_metrics = get_best_metrics(history)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìä TRAINING RESULTS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nüèÜ BEST PERFORMANCE:\")\n",
        "print(f\"   ‚Ä¢ Best epoch: {best_metrics['best_epoch']} / {best_metrics['total_epochs']}\")\n",
        "print(f\"   ‚Ä¢ Best validation accuracy: {best_metrics['best_val_accuracy']*100:.2f}%\")\n",
        "print(f\"   ‚Ä¢ Best validation loss: {best_metrics['best_val_loss']:.4f}\")\n",
        "\n",
        "if 'best_val_precision' in best_metrics:\n",
        "    print(f\"   ‚Ä¢ Best validation precision: {best_metrics['best_val_precision']*100:.2f}%\")\n",
        "if 'best_val_recall' in best_metrics:\n",
        "    print(f\"   ‚Ä¢ Best validation recall: {best_metrics['best_val_recall']*100:.2f}%\")\n",
        "\n",
        "print(f\"\\nüìà FINAL METRICS:\")\n",
        "print(f\"   ‚Ä¢ Training accuracy: {best_metrics['final_train_accuracy']*100:.2f}%\")\n",
        "print(f\"   ‚Ä¢ Validation accuracy: {best_metrics['final_val_accuracy']*100:.2f}%\")\n",
        "print(f\"   ‚Ä¢ Training loss: {best_metrics['final_train_loss']:.4f}\")\n",
        "print(f\"   ‚Ä¢ Validation loss: {best_metrics['final_val_loss']:.4f}\")\n",
        "\n",
        "# Check for overfitting\n",
        "overfit_gap = best_metrics['final_train_accuracy'] - best_metrics['final_val_accuracy']\n",
        "print(f\"\\nüîç OVERFITTING ANALYSIS:\")\n",
        "print(f\"   ‚Ä¢ Train-Val accuracy gap: {overfit_gap*100:.2f}%\")\n",
        "if overfit_gap > 0.1:\n",
        "    print(f\"   ‚ö†Ô∏è Warning: Possible overfitting detected. Consider more regularization.\")\n",
        "elif overfit_gap < 0:\n",
        "    print(f\"   ‚ö†Ô∏è Warning: Possible underfitting. Consider training longer or more capacity.\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ Good generalization - model is well balanced.\")"
      ],
      "metadata": {
        "id": "results_summary"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Save Final Model & Training Report"
      ],
      "metadata": {
        "id": "save_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_training_report(history, metrics, config, save_dir, timestamp):\n",
        "    \"\"\"\n",
        "    Save comprehensive training report.\n",
        "    \"\"\"\n",
        "    report = {\n",
        "        'phase': 'Phase 6: Model Training & Hyperparameter Tuning',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'training_id': timestamp,\n",
        "        'configuration': {\n",
        "            'model_name': 'PotatoDisease_MobileNetV2',\n",
        "            'input_shape': list(config['img_shape']),\n",
        "            'num_classes': int(config['num_classes']),\n",
        "            'batch_size': int(config['batch_size']),\n",
        "            'learning_rate': float(config['learning_rate']),\n",
        "            'epochs_configured': int(config['epochs']),\n",
        "            'fine_tune_layers': int(config['fine_tune_layers'])\n",
        "        },\n",
        "        'dataset': {\n",
        "            'train_samples': int(config['train_samples']),\n",
        "            'val_samples': int(config['val_samples']),\n",
        "            'test_samples': int(config['test_samples'])\n",
        "        },\n",
        "        'training_results': metrics,\n",
        "        'training_time_minutes': float(config['training_time'] / 60),\n",
        "        'model_saved_to': os.path.join(save_dir, 'PotatoDisease_MobileNetV2_best.keras')\n",
        "    }\n",
        "    \n",
        "    # Save report\n",
        "    report_path = os.path.join(save_dir, f'training_report_{timestamp}.json')\n",
        "    with open(report_path, 'w') as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "    \n",
        "    return report_path\n",
        "\n",
        "\n",
        "# Prepare config\n",
        "training_config = {\n",
        "    'img_shape': IMG_SHAPE,\n",
        "    'num_classes': NUM_CLASSES,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'epochs': EPOCHS,\n",
        "    'fine_tune_layers': FINE_TUNE_LAYERS,\n",
        "    'train_samples': train_gen.samples,\n",
        "    'val_samples': val_gen.samples,\n",
        "    'test_samples': test_gen.samples,\n",
        "    'training_time': training_time\n",
        "}\n",
        "\n",
        "# Save report\n",
        "report_path = save_training_report(history, best_metrics, training_config, MODEL_SAVE_DIR, timestamp)\n",
        "\n",
        "# Save final model (in addition to best checkpoint)\n",
        "final_model_path = os.path.join(MODEL_SAVE_DIR, f'PotatoDisease_MobileNetV2_final_{timestamp}.keras')\n",
        "model.save(final_model_path)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üíæ MODEL & REPORTS SAVED\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nüìÅ Files saved to: {MODEL_SAVE_DIR}\")\n",
        "print(f\"   ‚Ä¢ Best model: PotatoDisease_MobileNetV2_best.keras\")\n",
        "print(f\"   ‚Ä¢ Final model: PotatoDisease_MobileNetV2_final_{timestamp}.keras\")\n",
        "print(f\"   ‚Ä¢ Training report: training_report_{timestamp}.json\")\n",
        "print(f\"\\nüìÅ Logs saved to: {LOGS_DIR}\")\n",
        "print(f\"   ‚Ä¢ Training log: training_log_{timestamp}.csv\")\n",
        "print(f\"   ‚Ä¢ Training curves: training_curves_{timestamp}.png\")"
      ],
      "metadata": {
        "id": "save_model_report"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Quick Validation on Test Set (Preview)"
      ],
      "metadata": {
        "id": "quick_test_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick evaluation on test set\n",
        "print(\"\\nüß™ Quick Test Set Evaluation...\")\n",
        "\n",
        "test_results = model.evaluate(test_gen, verbose=1)\n",
        "\n",
        "print(f\"\\nüìä Test Set Results:\")\n",
        "print(f\"   ‚Ä¢ Test Loss: {test_results[0]:.4f}\")\n",
        "print(f\"   ‚Ä¢ Test Accuracy: {test_results[1]*100:.2f}%\")\n",
        "if len(test_results) > 2:\n",
        "    print(f\"   ‚Ä¢ Test Precision: {test_results[2]*100:.2f}%\")\n",
        "if len(test_results) > 3:\n",
        "    print(f\"   ‚Ä¢ Test Recall: {test_results[3]*100:.2f}%\")"
      ],
      "metadata": {
        "id": "quick_test"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Hyperparameter Tuning Experiments (Optional)\n",
        "\n",
        "Run this section to experiment with different hyperparameters."
      ],
      "metadata": {
        "id": "tuning_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== HYPERPARAMETER EXPERIMENTS =====\n",
        "# Uncomment and modify to run experiments\n",
        "\n",
        "RUN_EXPERIMENTS = False  # Set to True to run hyperparameter search\n",
        "\n",
        "if RUN_EXPERIMENTS:\n",
        "    # Define hyperparameter grid\n",
        "    experiments = [\n",
        "        {'lr': 0.001, 'batch': 32, 'fine_tune': 10, 'name': 'high_lr'},\n",
        "        {'lr': 0.0001, 'batch': 16, 'fine_tune': 20, 'name': 'small_batch'},\n",
        "        {'lr': 0.00005, 'batch': 32, 'fine_tune': 30, 'name': 'more_finetune'},\n",
        "    ]\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for exp in experiments:\n",
        "        print(f\"\\nüî¨ Experiment: {exp['name']}\")\n",
        "        print(f\"   LR: {exp['lr']}, Batch: {exp['batch']}, Fine-tune: {exp['fine_tune']}\")\n",
        "        \n",
        "        # Create new data generators with different batch size\n",
        "        train_g, val_g, _ = create_data_generators(\n",
        "            TRAIN_DIR, VAL_DIR, TEST_DIR, IMG_SIZE, exp['batch']\n",
        "        )\n",
        "        \n",
        "        # Build and train model\n",
        "        exp_model = build_model(IMG_SHAPE, NUM_CLASSES, exp['lr'], exp['fine_tune'])\n",
        "        \n",
        "        exp_callbacks = [\n",
        "            EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "        ]\n",
        "        \n",
        "        exp_history = exp_model.fit(\n",
        "            train_g,\n",
        "            epochs=15,  # Reduced epochs for experiments\n",
        "            validation_data=val_g,\n",
        "            callbacks=exp_callbacks,\n",
        "            verbose=0\n",
        "        )\n",
        "        \n",
        "        best_val_acc = max(exp_history.history['val_accuracy'])\n",
        "        results.append({\n",
        "            'name': exp['name'],\n",
        "            'lr': exp['lr'],\n",
        "            'batch': exp['batch'],\n",
        "            'fine_tune': exp['fine_tune'],\n",
        "            'best_val_acc': best_val_acc\n",
        "        })\n",
        "        print(f\"   ‚úÖ Best val accuracy: {best_val_acc*100:.2f}%\")\n",
        "        \n",
        "        # Clear memory\n",
        "        del exp_model\n",
        "        tf.keras.backend.clear_session()\n",
        "    \n",
        "    # Show experiment results\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"üìä HYPERPARAMETER EXPERIMENT RESULTS\")\n",
        "    print(\"=\" * 50)\n",
        "    for r in sorted(results, key=lambda x: x['best_val_acc'], reverse=True):\n",
        "        print(f\"\\n   {r['name']}:\")\n",
        "        print(f\"   LR={r['lr']}, Batch={r['batch']}, Fine-tune={r['fine_tune']}\")\n",
        "        print(f\"   ‚Üí Val Accuracy: {r['best_val_acc']*100:.2f}%\")\n",
        "else:\n",
        "    print(\"\\n‚è≠Ô∏è Hyperparameter experiments skipped.\")\n",
        "    print(\"   Set RUN_EXPERIMENTS = True to run experiments.\")"
      ],
      "metadata": {
        "id": "hyperparameter_tuning"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Phase 6 Complete!\n",
        "\n",
        "**Training Summary:**\n",
        "- ‚úÖ Model trained successfully\n",
        "- ‚úÖ Best model checkpoint saved\n",
        "- ‚úÖ Training curves generated\n",
        "- ‚úÖ Training report saved\n",
        "\n",
        "**Saved Files:**\n",
        "```\n",
        "/content/drive/MyDrive/DrukFarm/models/\n",
        "‚îú‚îÄ‚îÄ PotatoDisease_MobileNetV2_best.keras     (best checkpoint)\n",
        "‚îú‚îÄ‚îÄ PotatoDisease_MobileNetV2_final_*.keras  (final model)\n",
        "‚îî‚îÄ‚îÄ training_report_*.json                   (training report)\n",
        "\n",
        "/content/drive/MyDrive/DrukFarm/training_logs/\n",
        "‚îú‚îÄ‚îÄ training_log_*.csv                       (epoch-by-epoch metrics)\n",
        "‚îî‚îÄ‚îÄ training_curves_*.png                    (visualization)\n",
        "```\n",
        "\n",
        "**Next Steps:**\n",
        "- Phase 7: Model Evaluation & Testing"
      ],
      "metadata": {
        "id": "conclusion"
      }
    }
  ]
}
